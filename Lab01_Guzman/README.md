# Laboratorio 01 ‚Äì Multiplicaci√≥n de Matrices con OpenMP

Este laboratorio corresponde al curso **Introducci√≥n a Sistemas Distribuidos**.  
El objetivo fue implementar, corregir, documentar y probar un algoritmo de **multiplicaci√≥n de matrices cl√°sica (MM)** en C, paralelizado con **OpenMP**, y dise√±ar un plan de pruebas de carga que permita evaluar su rendimiento.

---

## üìå Descripci√≥n del laboratorio

- Se parti√≥ de un c√≥digo base en C que implementa la multiplicaci√≥n de matrices.  
- Se corrigi√≥ y document√≥ el c√≥digo, agregando soporte a paralelismo con OpenMP.  
- Se adapt√≥ un **Makefile** para automatizar la compilaci√≥n del programa.  
- Se cre√≥ un **script de automatizaci√≥n (`lanzador.pl`)** para ejecutar m√∫ltiples pruebas con diferentes tama√±os de matrices y distintos niveles de paralelismo.  
- Se dise√±√≥ un **plan de pruebas de carga** con 12 dimensiones menores a 14.000 y con hilos: **1, 4, 8, 16 y 20**.  
- Los resultados se consolidaron en archivos `.dat` y en un PDF con la tabla final de tiempos promedios y desviaciones est√°ndar.

---

## üìÇ Archivos incluidos

- **`mmClasicaOpenMP.c`** ‚Üí C√≥digo fuente en C del algoritmo corregido y documentado.  
- **`mmClasicaOpenMP`** ‚Üí Ejecutable generado a partir del c√≥digo fuente.  
- **`Makefile`** ‚Üí Script para compilar autom√°ticamente el programa con soporte OpenMP.  
- **`lanzador.pl`** ‚Üí Script en Perl que ejecuta el programa con los diferentes tama√±os y hilos, generando resultados en `.dat`.  
- **`dat.zip`** ‚Üí Carpeta comprimida que contiene todos los resultados de las pruebas experimentales.  
- **`Tabla_Resultados.pdf`** ‚Üí Documento que presenta la tabla consolidada de tiempos promedios y desviaciones est√°ndar.  
- **`README.md`** ‚Üí Este documento, que incluye el an√°lisis y las conclusiones del laboratorio.  

---

## üß™ Plan de pruebas

- **Dimensiones usadas:** 11 tama√±os diferentes de matrices, todos menores a 14.000.  
- **Niveles de paralelismo:** 1, 4, 8, 16 y 20 hilos.  
- **Repeticiones:** Cada combinaci√≥n se ejecut√≥ 30 veces para reducir el ruido del sistema operativo y sustentar estad√≠sticamente los resultados.  

Cada corrida registra el **tiempo de ejecuci√≥n en microsegundos**, permitiendo calcular promedios y desviaciones est√°ndar para cada configuraci√≥n.

---

## üìä Resultados

- Los resultados detallados de todas las corridas est√°n disponibles en [`dat.zip`](./dat.zip).  
- La tabla consolidada de tiempos promedios y desviaciones est√°ndar se encuentra en **[`Tabla_Resultados.pdf`](./Tabla_Resultados.pdf)**.  

---

## üîé An√°lisis de resultados

Al observar los valores promedios y sus desviaciones est√°ndar (v√©ase `Tabla_Resultados.pdf`), se aprecia una tendencia consistente: **los tiempos descienden al aumentar el n√∫mero de hilos**, pero el beneficio depende del tama√±o de la matriz. En **tama√±os peque√±os**, la sobrecarga asociada a la creaci√≥n y sincronizaci√≥n de hilos reduce la ganancia de paralelizar y, en algunos casos, la **variabilidad relativa** (desviaci√≥n est√°ndar/medio) resulta m√°s perceptible. A medida que el tama√±o **crece a escalas medianas y grandes**, el trabajo √∫til por hilo aumenta, el **tiempo promedio** cae de manera m√°s marcada y la desviaci√≥n est√°ndar se mantiene en rangos acotados, lo que sugiere **estabilidad** en las mediciones pese a las cargas alternas del sistema operativo.

El patr√≥n de **escalamiento** muestra mejoras claras al pasar de 1 a 4 u 8 hilos; sin embargo, al escalar hacia 16 y 20 hilos la **mejora marginal** tiende a disminuir, reflejando la t√≠pica **eficiencia decreciente** de la paralelizaci√≥n en memoria compartida: parte del tiempo se consume en sincronizaci√≥n y en l√≠mites propios de la arquitectura (ancho de banda de memoria, jerarqu√≠a de cach√©s). En conjunto, el **promedio** sirve como estimador robusto del rendimiento esperado, mientras que la **desviaci√≥n est√°ndar** acota la variaci√≥n entre corridas repetidas, cumpliendo el objetivo de **sustento estad√≠stico**. As√≠, los datos respaldan que **OpenMP resulta provechoso** especialmente para matrices medianas y grandes, con un punto de equilibrio donde a√±adir m√°s hilos aporta cada vez menos reducci√≥n de tiempo.

---

## ‚úÖ Conclusiones

El laboratorio demuestra que la **multiplicaci√≥n de matrices con OpenMP** obtiene **mejoras de rendimiento significativas** al incrementar el n√∫mero de hilos en tama√±os medianos y grandes, mientras que en tama√±os peque√±os la sobrecarga de paralelizaci√≥n limita los beneficios. El tratamiento estad√≠stico mediante **promedios y desviaciones est√°ndar** ‚Äîcalculados a partir de m√∫ltiples repeticiones‚Äî **sustenta la validez** de los resultados frente a ruidos y variaciones del sistema operativo. Se cumplieron los objetivos: **corregir, documentar y probar** el algoritmo; **automatizar** su compilaci√≥n y ejecuci√≥n; y **dise√±ar** un plan de pruebas de carga **con respaldo estad√≠stico**.
